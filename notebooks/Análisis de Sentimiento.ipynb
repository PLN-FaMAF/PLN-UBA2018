{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de Sentimiento\n",
    "\n",
    "## Corpus de Tweets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentiment.tass import InterTASSReader\n",
    "\n",
    "reader = InterTASSReader('TASS/InterTASS/tw_faces4tassTrain1000rc.xml')\n",
    "tweets = list(reader.tweets())  # iterador sobre los tweets\n",
    "X = list(reader.X())  # iterador sobre los contenidos de los tweets\n",
    "y = list(reader.y())  # iterador sobre las polaridades de los tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(tweets[0].keys())\n",
    "#print(X[0])\n",
    "#print(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento y Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run sentiment/scripts/train.py -m clf -c maxent -o clf_maxent\n",
    "# %run sentiment/scripts/curve.py -m clf -c maxent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment P:\n",
      "  Precision: 55.30% (120/217)\n",
      "  Recall: 76.92% (120/156)\n",
      "  F1: 64.34%\n",
      "Sentiment N:\n",
      "  Precision: 67.18% (131/195)\n",
      "  Recall: 59.82% (131/219)\n",
      "  F1: 63.29%\n",
      "Sentiment NEU:\n",
      "  Precision: 15.00% (3/20)\n",
      "  Recall: 4.35% (3/69)\n",
      "  F1: 6.74%\n",
      "Sentiment NONE:\n",
      "  Precision: 29.73% (22/74)\n",
      "  Recall: 35.48% (22/62)\n",
      "  F1: 32.35%\n",
      "Accuracy: 54.55% (276/506)\n",
      "Macro-Precision: 41.80%\n",
      "Macro-Recall: 44.14%\n",
      "Macro-F1: 42.94%\n",
      "\tP\tN\tNEU\tNONE\n",
      "P\t120\t20\t7\t9\t\n",
      "N\t45\t131\t9\t34\t\n",
      "NEU\t33\t24\t3\t9\t\n",
      "NONE\t19\t20\t1\t22\t\n"
     ]
    }
   ],
   "source": [
    "%run sentiment/scripts/eval.py -i clf_maxent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jugando con el Clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@noseashetero 1000/10 de verdad a ti que voy a decir petarda que te quiero más que a mí mismo  ✨\n",
      "['N']\n"
     ]
    }
   ],
   "source": [
    "pipeline = model._pipeline\n",
    "x = X[0]\n",
    "print(x)\n",
    "y = pipeline.predict(['estamos todos muy tristes'])\n",
    "print(y)\n",
    "#P = pipeline.predict_proba([x])\n",
    "# D = pipeline.decision_function([x])\n",
    "# print(D)\n",
    "# print(x)\n",
    "# print(y)\n",
    "# print(P)\n",
    "# print(type(P))  P es un array de numpy (o sea, una matriz)\n",
    "#print(pipeline.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis del Modelo y Errores\n",
    "\n",
    "Para el clasificador maxent podemos consultar las características que más favorecen o desfavorecen cada clase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N:\n",
      "\tport bes ) enhorabuen maravill ([-1.73672947 -1.68388457 -1.66122784 -1.49959025 -1.49320248])\n",
      "\tdolor mal peor denunci trist ([1.86992474 1.89365963 2.0767024  2.10640275 2.36932745])\n",
      "NEU:\n",
      "\tsalud not_porqu president enhorabuen 6 ([-1.42524089 -1.22799446 -1.09372826 -1.03402328 -0.99906009])\n",
      "\texpect camps perdon convers tranquil ([1.25371167 1.35403923 1.39586498 1.59507114 1.72814477])\n",
      "NONE:\n",
      "\tencant mal feliz graci apoy ([-2.17367693 -2.09441975 -1.97057239 -1.85226463 -1.83706697])\n",
      "\tnot_otr posesion 7714 reunion port ([1.2894653  1.30457447 1.36366543 1.39630086 2.1885628 ])\n",
      "P:\n",
      "\tblanc urdangarin trist cuent critic ([-1.59395065 -1.53968117 -1.43379717 -1.42313938 -1.39628165])\n",
      "\tgraci homenaj maravill encant enhorabuen ([1.96062818 2.13499616 2.20104348 2.47710913 2.62374376])\n"
     ]
    }
   ],
   "source": [
    "# el model ya quedó cargado al haber corrido eval.py\n",
    "pipeline = model._pipeline\n",
    "# norm = pipeline.named_steps['norm']\n",
    "vect = pipeline.named_steps['vect']\n",
    "clf = pipeline.named_steps['clf']\n",
    "\n",
    "from sentiment.analysis import print_maxent_features\n",
    "print_maxent_features(vect, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El script de evaluación también calcula una matriz de confusión detallada \"cm_items\" para ver en qué instancias falla. Veamos las instancias que son negativas y fueron marcadas como positivas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(cm_items['N', 'P'])\n",
    "X2 = [X[i] for i in cm_items['N', 'P']]  # obtenemos los contenidos\n",
    "print(X2[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando predict_proba podemos calcular los \"peores\" errores, esto es, los que más favorecieron P por encima de N:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = pipeline.predict_proba(X2)  # calculamos las probabilidades para todas las clases\n",
    "# print(P.shape)\n",
    "# print(P[0])\n",
    "# print(pipeline.classes_)\n",
    "delta = P[:,3] - P[:,0]  # diferencia entre prob de P y prob de N\n",
    "# print(delta[0])\n",
    "# print(delta.shape)\n",
    "sorted_X2 = sorted(zip(X2, delta), key=lambda x: x[1], reverse=True)   # ordenamos de mayor a menor\n",
    "sorted_X2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pipeline.predict_proba(['@sport Teneis el ojino como la bandera de Japón ,hijos de la gran puta ']))\n",
    "# print(pipeline.decision_function(['JA JA JA JA JA']))\n",
    "pipeline.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Acá parece que las repeticiones afectan mucho!\n",
    "\n",
    "También se puede ver para una instancia particular, qué features tiene y cuánto pesan para cada clase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentiment.analysis import print_feature_weights_for_item\n",
    "#x = sorted_X2[0][0]\n",
    "# print(x)\n",
    "print_feature_weights_for_item(vect, clf, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalización\n",
    "\n",
    "Veamos por ejemplo cómo eliminar URLs y menciones de usuarios usando expresiones regulares. Tomemos un tweet de ejemplo que tenga ambas cosas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [x for x in X if 'http' in x and '@' in x][1]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mentions = r'(?:@[^\\s]+)'  # una arroba seguida de uno o más caracteres que no son de espaciado\n",
    "urls = r'(?:https?\\://t.co/[\\w]+)'  # una URL http o https. \\w acepta letras, números y '_'.\n",
    "\n",
    "import re\n",
    "re.sub(mentions, '', x)\n",
    "# re.sub(urls, '', x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negaciones\n",
    "\n",
    "Veamos una forma simple de manejar las negaciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = [x for x in X if 'no' in x.split()][0]\n",
    "# x\n",
    "x = 'las tengo pero aún no las he leído . Caerán prontito'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = x.split()\n",
    "new_tokens = []\n",
    "negate = False\n",
    "for token in tokens:\n",
    "    if token in ['no', 'tampoco']:\n",
    "        negate = True\n",
    "    elif token == '.':\n",
    "        negate = False\n",
    "    elif negate:\n",
    "        token = 'NOT_' + token\n",
    "    new_tokens.append(token)\n",
    "\n",
    "' '.join(new_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emojis\n",
    "\n",
    "Los emojis no deben ser filtrados ya que expresan sentimiento. Veamos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install emoji\n",
    "import emoji\n",
    "emojis = set(emoji.UNICODE_EMOJI)\n",
    "x = [x for x in X if emojis & set(x.split())][1]  # buscamos algún ejemplo con emojis\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "token_pattern = r\"(?u)\\b\\w\\w+\\b\"  # este es el patrón de tokenización que usa el count vectorizer\n",
    "re.findall(token_pattern, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que este tokenizador elimina los emojis y la puntuación. Veamos el tokenizador de NLTK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nltk import word_tokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tkn = TweetTokenizer()\n",
    "tkn.tokenize(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Mejor!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
