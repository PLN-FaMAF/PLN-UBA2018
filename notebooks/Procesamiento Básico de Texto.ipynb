{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK\n",
    "\n",
    "Descargar corpus y modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()\n",
    "# instalar corpus gutenberg y modelo punkt (tokenizador y segmentador)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternativamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/francolq/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     /home/francolq/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gutenberg.sents('austen-emma.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estadísticas Básicas\n",
    "\n",
    "Versión básica con diccionarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fearless': 1,\n",
       " 'involvement': 1,\n",
       " 'instigator': 1,\n",
       " 'uninterruptedly': 1,\n",
       " 'Hughes': 3,\n",
       " 'Farmer': 1,\n",
       " 'Making': 1,\n",
       " 'divisions': 3,\n",
       " 'unpleasant': 13,\n",
       " 'fried': 2,\n",
       " 'short': 67,\n",
       " 'threaten': 1,\n",
       " 'convenient': 5,\n",
       " 'Something': 8,\n",
       " 'mails': 1,\n",
       " 'eaten': 3,\n",
       " 'faultless': 1,\n",
       " 'distance': 25,\n",
       " 'Extracts': 2,\n",
       " 'grandpapa': 2,\n",
       " 'memory': 10,\n",
       " 'reproached': 1,\n",
       " 'mine': 25,\n",
       " 'taking': 28,\n",
       " 'travels': 1,\n",
       " 'dinner': 47,\n",
       " 'pet': 1,\n",
       " 'villain': 1,\n",
       " 'Smiths': 1,\n",
       " 'insulted': 1,\n",
       " 'were': 591,\n",
       " 'Day': 2,\n",
       " 'motto': 1,\n",
       " 'crossed': 6,\n",
       " 'claiming': 1,\n",
       " 'transcribed': 2,\n",
       " 'marriages': 1,\n",
       " 'excepting': 11,\n",
       " 'assuming': 4,\n",
       " 'cope': 1,\n",
       " 'spirited': 3,\n",
       " 'knowing': 26,\n",
       " 'positively': 10,\n",
       " 'canvassing': 1,\n",
       " 'bounds': 1,\n",
       " 'sufficiency': 1,\n",
       " 'wanting': 33,\n",
       " 'fuss': 1,\n",
       " 'kings': 2,\n",
       " 'considerably': 4,\n",
       " 'fidgeting': 1,\n",
       " 'collation': 1,\n",
       " 'inseparably': 1,\n",
       " 'commission': 5,\n",
       " 'Cowper': 1,\n",
       " 'civil': 13,\n",
       " 'altogether': 22,\n",
       " 'Wiltshire': 1,\n",
       " 'damps': 1,\n",
       " 'pleased': 47,\n",
       " 'carriages': 11,\n",
       " 'altar': 1,\n",
       " 'bewitching': 2,\n",
       " 'abusing': 2,\n",
       " 'war': 1,\n",
       " 'detaining': 2,\n",
       " 'confiding': 1,\n",
       " 'headache': 4,\n",
       " 'medium': 2,\n",
       " 'sang': 3,\n",
       " 'Late': 1,\n",
       " 'ensure': 2,\n",
       " 'chances': 5,\n",
       " 'energy': 3,\n",
       " 'admiration': 24,\n",
       " 'clownish': 2,\n",
       " 'Anywhere': 1,\n",
       " 'ceremony': 7,\n",
       " 'prophecies': 1,\n",
       " 'Within': 4,\n",
       " 'punishment': 4,\n",
       " 'Tuesday': 7,\n",
       " 'undertaken': 1,\n",
       " 'wife': 68,\n",
       " 'liberality': 2,\n",
       " 'confirming': 1,\n",
       " 'add': 11,\n",
       " 'exulting': 2,\n",
       " 'gravel': 2,\n",
       " 'sublime': 1,\n",
       " 'manner': 75,\n",
       " 'desired': 12,\n",
       " 'alert': 3,\n",
       " 'singularly': 1,\n",
       " 'privations': 4,\n",
       " 'practicable': 3,\n",
       " 'glanced': 2,\n",
       " 'Nothing': 19,\n",
       " 'assurance': 8,\n",
       " 'Shakespeare': 1,\n",
       " 'dirt': 1,\n",
       " 'desires': 2,\n",
       " 'whenever': 22,\n",
       " 'borrow': 1,\n",
       " 'established': 5,\n",
       " 'resemblance': 5,\n",
       " 'remains': 5,\n",
       " 'quarrelled': 4,\n",
       " 'Cautious': 1,\n",
       " 'acquainted': 33,\n",
       " 'vicarage': 5,\n",
       " 'judicious': 3,\n",
       " 'whatever': 16,\n",
       " 'disagreement': 3,\n",
       " 'sets': 1,\n",
       " 'unpretending': 3,\n",
       " 'refreshment': 2,\n",
       " 'dissipation': 1,\n",
       " 'perusal': 1,\n",
       " 'issued': 1,\n",
       " 'continuance': 2,\n",
       " 'disappointed': 20,\n",
       " 'compliment': 31,\n",
       " 'carriage': 69,\n",
       " 'unsteadiness': 2,\n",
       " 'differently': 11,\n",
       " 'prevented': 9,\n",
       " 'prisoner': 1,\n",
       " 'induced': 12,\n",
       " 'since': 63,\n",
       " 'overrated': 1,\n",
       " 'Ours': 1,\n",
       " 'collections': 1,\n",
       " 'nicety': 1,\n",
       " 'obstinate': 1,\n",
       " 'caprices': 1,\n",
       " 'contingencies': 1,\n",
       " 'preferred': 10,\n",
       " 'regularly': 3,\n",
       " 'bottom': 3,\n",
       " 'Holyhead': 1,\n",
       " 'disgust': 5,\n",
       " 'fact': 24,\n",
       " 'preparations': 3,\n",
       " 'pass': 30,\n",
       " 'curiosity': 28,\n",
       " '_at_': 2,\n",
       " 'teachers': 3,\n",
       " 'excite': 3,\n",
       " 'addressing': 9,\n",
       " 'condolence': 1,\n",
       " 'temper': 36,\n",
       " 'CHURCHILL': 1,\n",
       " 'unmentioned': 1,\n",
       " 'apiece': 1,\n",
       " 'truly': 12,\n",
       " 'waste': 2,\n",
       " 'staid': 8,\n",
       " 'absences': 1,\n",
       " '----': 1,\n",
       " 'sad': 25,\n",
       " 'does': 125,\n",
       " 'objections': 4,\n",
       " 'baby': 6,\n",
       " 'interference': 7,\n",
       " 'corrected': 1,\n",
       " 'due': 23,\n",
       " 'parts': 2,\n",
       " 'guilt': 3,\n",
       " 'homewards': 1,\n",
       " 'particularly': 46,\n",
       " 'thing': 398,\n",
       " 'mile': 11,\n",
       " 'unseasonableness': 1,\n",
       " 'maintenance': 2,\n",
       " 'concert': 1,\n",
       " 'excess': 1,\n",
       " 'respective': 1,\n",
       " 'mercy': 3,\n",
       " 'awake': 2,\n",
       " 'paused': 6,\n",
       " 'eats': 2,\n",
       " 'favourite': 23,\n",
       " 'nominal': 1,\n",
       " 'spontaneous': 1,\n",
       " 'festivity': 1,\n",
       " 'shifted': 1,\n",
       " 'forswear': 1,\n",
       " 'reconcile': 2,\n",
       " 'irresolute': 2,\n",
       " 'Trouble': 1,\n",
       " 'eyes': 51,\n",
       " 'ceaseless': 2,\n",
       " 'killed': 4,\n",
       " '_The_': 1,\n",
       " 'drizzle': 1,\n",
       " 'thankful': 5,\n",
       " 'exquisite': 8,\n",
       " 'chattering': 1,\n",
       " 'broke': 1,\n",
       " 'instantly': 14,\n",
       " 'slightingly': 1,\n",
       " 'Dr': 2,\n",
       " 'complacency': 3,\n",
       " 'footstep': 2,\n",
       " 'suffering': 16,\n",
       " 'accommodation': 6,\n",
       " 'want': 89,\n",
       " 'rheumatic': 1,\n",
       " 'Donwell': 49,\n",
       " 'anxiously': 6,\n",
       " 'ult': 1,\n",
       " 'belonged': 6,\n",
       " 'congratulatory': 2,\n",
       " 'detain': 2,\n",
       " 'acquiescence': 5,\n",
       " 'management': 1,\n",
       " 'ancient': 1,\n",
       " 'neighbour': 8,\n",
       " 'casements': 1,\n",
       " 'amongst': 3,\n",
       " 'who': 281,\n",
       " 'pre': 1,\n",
       " 'your': 337,\n",
       " 'conveying': 1,\n",
       " 'feebleness': 1,\n",
       " 'games': 1,\n",
       " 'diffident': 2,\n",
       " 'tittle': 1,\n",
       " 'clearly': 3,\n",
       " 'ages': 2,\n",
       " 'lives': 7,\n",
       " 'division': 3,\n",
       " 'apprehended': 3,\n",
       " 'citizen': 1,\n",
       " 'listener': 1,\n",
       " 'fame': 4,\n",
       " 'lived': 25,\n",
       " 'prejudices': 1,\n",
       " 'illumination': 1,\n",
       " 'conversation': 42,\n",
       " 'relapse': 1,\n",
       " 'occurrence': 3,\n",
       " 'Martins': 13,\n",
       " 'expression': 9,\n",
       " 'fireside': 4,\n",
       " 'Does': 5,\n",
       " '_little_': 2,\n",
       " 'Aunt': 1,\n",
       " 'expiration': 1,\n",
       " 'miserably': 3,\n",
       " 'prodigy': 2,\n",
       " 'impartial': 1,\n",
       " 'limited': 3,\n",
       " 'inclined': 6,\n",
       " 'already': 45,\n",
       " 'entreaties': 6,\n",
       " 'contradiction': 3,\n",
       " 'Find': 1,\n",
       " 'complaints': 4,\n",
       " 'heiress': 1,\n",
       " 'seats': 1,\n",
       " 'lessons': 1,\n",
       " 'overhear': 1,\n",
       " 'elect': 1,\n",
       " 'asperity': 1,\n",
       " 'flower': 1,\n",
       " 'allowing': 5,\n",
       " 'involved': 6,\n",
       " 'attitude': 3,\n",
       " 'kingdoms': 1,\n",
       " 'parting': 13,\n",
       " 'recall': 3,\n",
       " 'quarter': 25,\n",
       " 'asks': 3,\n",
       " 'dispelled': 1,\n",
       " 'falsehoods': 1,\n",
       " 'Quite': 13,\n",
       " 'suspect': 21,\n",
       " 'chance': 20,\n",
       " 'inelegance': 1,\n",
       " 'acre': 1,\n",
       " 'dirty': 5,\n",
       " 'knight': 1,\n",
       " 'sickness': 2,\n",
       " 'envy': 6,\n",
       " 'Bath': 19,\n",
       " 'mount': 1,\n",
       " 'errantry': 1,\n",
       " 'estimated': 1,\n",
       " 'overthrow': 1,\n",
       " 'Absence': 1,\n",
       " 'fetched': 2,\n",
       " 'rejoicing': 1,\n",
       " 'unfeignedly': 1,\n",
       " 'denotes': 1,\n",
       " 'prudence': 5,\n",
       " 'ever': 189,\n",
       " 'communicating': 2,\n",
       " 'persuade': 14,\n",
       " 'relief': 9,\n",
       " 'egg': 3,\n",
       " 'agreeableness': 2,\n",
       " 'blow': 3,\n",
       " 'hardened': 1,\n",
       " 'shells': 1,\n",
       " 'stir': 7,\n",
       " 'rewarded': 1,\n",
       " 'affectionate': 9,\n",
       " 'courts': 1,\n",
       " 'luck': 11,\n",
       " 'Give': 2,\n",
       " 'cavil': 1,\n",
       " 'active': 7,\n",
       " 'topic': 3,\n",
       " 'Otway': 5,\n",
       " 'reprehensible': 1,\n",
       " 'unfit': 4,\n",
       " 'own': 301,\n",
       " 'standers': 1,\n",
       " 'services': 1,\n",
       " 'Low': 1,\n",
       " 'gayest': 1,\n",
       " '_treasures_': 1,\n",
       " 'complains': 2,\n",
       " 'awe': 1,\n",
       " 'ingenious': 2,\n",
       " 'Astonished': 1,\n",
       " 'worse': 28,\n",
       " 'apparatus': 1,\n",
       " 'no': 616,\n",
       " 'disappearance': 3,\n",
       " 'replied': 79,\n",
       " 'Langham': 1,\n",
       " 'tried': 26,\n",
       " '_when_': 1,\n",
       " 'strikes': 3,\n",
       " 'meets': 1,\n",
       " 'faster': 2,\n",
       " 'complaisance': 2,\n",
       " '[': 2,\n",
       " 'bound': 1,\n",
       " 'entrance': 5,\n",
       " 'occasion': 28,\n",
       " 'honestly': 3,\n",
       " 'estimation': 3,\n",
       " 'embarrassing': 1,\n",
       " 'degrading': 3,\n",
       " 'indulged': 4,\n",
       " 'condemn': 2,\n",
       " 'grace': 8,\n",
       " 'excited': 6,\n",
       " 'mentioning': 5,\n",
       " 'Two': 7,\n",
       " 'infantry': 1,\n",
       " 'longing': 4,\n",
       " 'divert': 1,\n",
       " 'pleasantest': 3,\n",
       " 'studied': 2,\n",
       " '_Taylor_': 1,\n",
       " 'cautioned': 1,\n",
       " 'handled': 1,\n",
       " 'bar': 1,\n",
       " 'representations': 1,\n",
       " 'minutes': 53,\n",
       " 'constrained': 1,\n",
       " 'Name': 1,\n",
       " 'small': 30,\n",
       " 'threatening': 2,\n",
       " 'cockade': 1,\n",
       " 'battle': 1,\n",
       " 'cry': 1,\n",
       " 'disdain': 4,\n",
       " 'nods': 1,\n",
       " 'returning': 17,\n",
       " 'trimming': 2,\n",
       " 'prefer': 6,\n",
       " 'finger': 3,\n",
       " 'Oxford': 2,\n",
       " 'softest': 1,\n",
       " 'regretted': 5,\n",
       " 'besides': 14,\n",
       " 'articles': 1,\n",
       " 'matting': 1,\n",
       " 'presume': 10,\n",
       " 'antidote': 1,\n",
       " 'agreeable': 50,\n",
       " 'helpless': 2,\n",
       " 'characteristic': 1,\n",
       " 'roast': 4,\n",
       " 'Undoubtedly': 1,\n",
       " 'warmer': 6,\n",
       " 'alarmed': 7,\n",
       " 'XI': 3,\n",
       " 'shrunk': 1,\n",
       " 'settled': 39,\n",
       " 'marry': 63,\n",
       " 'persuasion': 11,\n",
       " 'summons': 2,\n",
       " 'proposition': 3,\n",
       " 'females': 2,\n",
       " '_as_': 1,\n",
       " 'moralising': 1,\n",
       " 'forbade': 1,\n",
       " 'As': 49,\n",
       " 'trusting': 3,\n",
       " 'welcomed': 4,\n",
       " 'puzzle': 2,\n",
       " 'consulting': 4,\n",
       " 'Forcing': 1,\n",
       " 'planning': 3,\n",
       " 'disturbance': 2,\n",
       " 'gardeners': 2,\n",
       " 'bow': 4,\n",
       " 'rule': 10,\n",
       " 'effort': 5,\n",
       " 'unfeeling': 3,\n",
       " 'Escape': 1,\n",
       " 'hundreds': 1,\n",
       " 'minority': 1,\n",
       " 'patience': 11,\n",
       " 'stay': 43,\n",
       " 'danced': 8,\n",
       " 'book': 11,\n",
       " 'counter': 2,\n",
       " 'dreamer': 2,\n",
       " 'across': 7,\n",
       " 'misconceptions': 1,\n",
       " 'began': 64,\n",
       " 'puzzled': 3,\n",
       " 'candour': 5,\n",
       " 'riding': 1,\n",
       " ':--\"': 2,\n",
       " 'vigour': 1,\n",
       " 'engrossing': 1,\n",
       " 'butter': 2,\n",
       " 'marries': 4,\n",
       " 'managed': 1,\n",
       " 'hazle': 2,\n",
       " 'shawl': 5,\n",
       " 'breaking': 3,\n",
       " 'cakes': 1,\n",
       " 'irrational': 1,\n",
       " 'Real': 1,\n",
       " 'regular': 17,\n",
       " 'hoped': 43,\n",
       " 'mis': 2,\n",
       " 'reigning': 1,\n",
       " 'troublesome': 9,\n",
       " 'patroness': 1,\n",
       " 'Dinner': 2,\n",
       " 'disclosure': 3,\n",
       " 'blush': 22,\n",
       " 'degradation': 4,\n",
       " 'brilliancy': 1,\n",
       " 'guessed': 7,\n",
       " 'longest': 3,\n",
       " 'undervalued': 1,\n",
       " 'apologised': 1,\n",
       " 'eagerly': 11,\n",
       " 'facts': 1,\n",
       " 'enter': 8,\n",
       " 'be': 1970,\n",
       " 'unperceived': 2,\n",
       " 'closest': 2,\n",
       " 'nobility': 1,\n",
       " 'serve': 3,\n",
       " 'Easter': 2,\n",
       " 'disgrace': 2,\n",
       " 'detained': 7,\n",
       " 'steadiness': 4,\n",
       " 'slowly': 6,\n",
       " 'inspire': 1,\n",
       " 'meetings': 6,\n",
       " 'unquestionably': 1,\n",
       " 'ordered': 10,\n",
       " 'confirmed': 5,\n",
       " 'grievances': 1,\n",
       " 'entitled': 3,\n",
       " 'tax': 1,\n",
       " 'motion': 5,\n",
       " 'landau': 7,\n",
       " 'systems': 1,\n",
       " 'muslins': 1,\n",
       " 'dreaming': 1,\n",
       " 'Sometimes': 2,\n",
       " 'hundred': 15,\n",
       " 'live': 17,\n",
       " 'hot': 11,\n",
       " 'despoiling': 1,\n",
       " 'apparent': 10,\n",
       " 'rode': 3,\n",
       " 'experience': 4,\n",
       " 'some': 248,\n",
       " '_refused_': 1,\n",
       " 'been': 759,\n",
       " 'vexed': 4,\n",
       " 'stanza': 1,\n",
       " 'untouched': 1,\n",
       " 'of': 4279,\n",
       " 'clothes': 1,\n",
       " \"!'\": 9,\n",
       " 'nursed': 3,\n",
       " 'likewise': 4,\n",
       " 'Rather': 1,\n",
       " 'goodness': 7,\n",
       " 'visibly': 2,\n",
       " '_must_': 4,\n",
       " 'unfelt': 1,\n",
       " 'also': 24,\n",
       " 'main': 2,\n",
       " 'implicitly': 1,\n",
       " 'effects': 5,\n",
       " 'exerting': 2,\n",
       " 'beautifully': 3,\n",
       " 'afternoon': 6,\n",
       " 'recollecting': 3,\n",
       " 'industry': 1,\n",
       " 'transgression': 1,\n",
       " 'without': 211,\n",
       " 'oath': 1,\n",
       " 'go': 129,\n",
       " 'existed': 1,\n",
       " 'accustomed': 2,\n",
       " 'rightly': 4,\n",
       " 'tremblings': 1,\n",
       " 'Otways': 1,\n",
       " 'wind': 5,\n",
       " 'day': 190,\n",
       " 'heightened': 1,\n",
       " 'chatty': 2,\n",
       " 'rubber': 1,\n",
       " 'unbleached': 1,\n",
       " 'authority': 6,\n",
       " 'allies': 1,\n",
       " 'prosings': 1,\n",
       " 'listeners': 1,\n",
       " 'audibly': 1,\n",
       " 'homely': 1,\n",
       " 'sketch': 3,\n",
       " 'letter': 109,\n",
       " 'Circumstances': 1,\n",
       " 'You': 303,\n",
       " 'constantly': 8,\n",
       " 'taught': 7,\n",
       " 'enviable': 1,\n",
       " 'practising': 2,\n",
       " 'readiest': 1,\n",
       " 'head': 40,\n",
       " 'tie': 1,\n",
       " 'informs': 1,\n",
       " 'loin': 3,\n",
       " 'pales': 1,\n",
       " 'enemies': 1,\n",
       " 'unknown': 4,\n",
       " 'thus': 12,\n",
       " 'ridden': 2,\n",
       " 'lord': 3,\n",
       " 'takes': 8,\n",
       " 'denoted': 1,\n",
       " 'remedy': 1,\n",
       " '_recollecting_': 1,\n",
       " 'deadening': 1,\n",
       " 'tied': 1,\n",
       " 'easy': 28,\n",
       " 'powerful': 5,\n",
       " 'risking': 1,\n",
       " 'announced': 5,\n",
       " 'reserve': 11,\n",
       " 'contemplating': 1,\n",
       " '_Her_': 2,\n",
       " 'repent': 6,\n",
       " 'umbrella': 1,\n",
       " '_just_': 4,\n",
       " 'operations': 1,\n",
       " 'begs': 1,\n",
       " 'sports': 1,\n",
       " 'claimed': 2,\n",
       " 'hated': 1,\n",
       " 'ending': 3,\n",
       " 'requires': 5,\n",
       " 'meal': 4,\n",
       " 'nobody': 54,\n",
       " 'spirits': 64,\n",
       " 'allusions': 1,\n",
       " 'amiable': 34,\n",
       " 'diffuses': 1,\n",
       " 'diligence': 1,\n",
       " 'incapable': 2,\n",
       " 'doing': 45,\n",
       " 'deference': 2,\n",
       " 'plotting': 1,\n",
       " 'gossips': 1,\n",
       " 'whichever': 1,\n",
       " 'players': 1,\n",
       " 'Used': 1,\n",
       " 'poet': 2,\n",
       " 'bailiff': 1,\n",
       " 'generosity': 4,\n",
       " 'accomplished': 11,\n",
       " 'According': 1,\n",
       " 'enormous': 1,\n",
       " '.--`': 5,\n",
       " 'values': 1,\n",
       " 'deathbed': 1,\n",
       " 'prosperity': 3,\n",
       " 'relative': 5,\n",
       " 'ingeniously': 1,\n",
       " 'greatest': 29,\n",
       " 'amounted': 1,\n",
       " 'harboured': 1,\n",
       " 'perfection': 10,\n",
       " 'unspent': 1,\n",
       " 'key': 4,\n",
       " '_greater_': 1,\n",
       " 'broiling': 1,\n",
       " 'stopt': 9,\n",
       " 'demurred': 1,\n",
       " 'captious': 2,\n",
       " 'flew': 2,\n",
       " 'sting': 1,\n",
       " 'imagines': 1,\n",
       " 'Should': 3,\n",
       " 'disengage': 2,\n",
       " 'bewitches': 1,\n",
       " 'encumbrance': 3,\n",
       " 'directions': 4,\n",
       " 'redeem': 1,\n",
       " 'Mitchell': 1,\n",
       " 'These': 18,\n",
       " '.]': 1,\n",
       " 'patiently': 1,\n",
       " 'covering': 1,\n",
       " 'hand': 53,\n",
       " \".'\": 32,\n",
       " 'reports': 1,\n",
       " 'ashamed': 28,\n",
       " 'estimable': 1,\n",
       " 'candlelight': 2,\n",
       " 'notch': 1,\n",
       " 'accuse': 1,\n",
       " 'elms': 1,\n",
       " '_present_': 1,\n",
       " 'merry': 2,\n",
       " 'harmonise': 1,\n",
       " 'part': 66,\n",
       " 'Granted': 1,\n",
       " 'form': 19,\n",
       " 'seeing': 51,\n",
       " 'Genlis': 1,\n",
       " 'debt': 1,\n",
       " 'Full': 2,\n",
       " 'gang': 1,\n",
       " 'Excepting': 2,\n",
       " 'causes': 4,\n",
       " 'Better': 7,\n",
       " 'withdrawn': 3,\n",
       " 'turns': 9,\n",
       " 'tidings': 3,\n",
       " 'arguments': 2,\n",
       " 'denied': 4,\n",
       " 'fervour': 1,\n",
       " 'astonishment': 6,\n",
       " 'convenience': 6,\n",
       " 'unreserved': 1,\n",
       " 'modes': 2,\n",
       " 'attachment': 48,\n",
       " 'wilfully': 1,\n",
       " 'fence': 1,\n",
       " 'remonstrated': 1,\n",
       " '1816': 1,\n",
       " 'despise': 1,\n",
       " 'ungenerous': 1,\n",
       " 'around': 13,\n",
       " 'emotions': 2,\n",
       " 'reminding': 2,\n",
       " 'influence': 24,\n",
       " 'said': 484,\n",
       " 'pushed': 4,\n",
       " 'Wickedness': 1,\n",
       " 'conceive': 5,\n",
       " 'bustle': 10,\n",
       " 'laughing': 17,\n",
       " 'relish': 1,\n",
       " 'describing': 2,\n",
       " 'Fortune': 1,\n",
       " 'novelty': 2,\n",
       " 'dissentient': 1,\n",
       " 'fro': 1,\n",
       " 'willing': 13,\n",
       " 'clever': 27,\n",
       " 'Altogether': 1,\n",
       " 'scornful': 1,\n",
       " 'deciding': 1,\n",
       " 'quiet': 25,\n",
       " 'affability': 1,\n",
       " 'bit': 5,\n",
       " 'Bates': 148,\n",
       " 'loveliness': 3,\n",
       " '_moment_': 1,\n",
       " 'talent': 9,\n",
       " 'devotion': 2,\n",
       " 'eyebrows': 2,\n",
       " 'forwards': 2,\n",
       " 'supposes': 1,\n",
       " 'arms': 2,\n",
       " 'fairy': 3,\n",
       " 'anticipation': 4,\n",
       " 'What': 102,\n",
       " 'Captain': 3,\n",
       " 'rationally': 2,\n",
       " 'misled': 2,\n",
       " 'consistently': 1,\n",
       " 'sofa': 5,\n",
       " 'Tell': 4,\n",
       " 'Anxious': 1,\n",
       " 'hesitatingly': 3,\n",
       " 'riddles': 2,\n",
       " 'sucking': 1,\n",
       " 'robe': 1,\n",
       " 'route': 1,\n",
       " 'pure': 1,\n",
       " 'Vigorous': 1,\n",
       " 'inflicting': 1,\n",
       " 'joyfully': 1,\n",
       " 'agreeably': 5,\n",
       " 'knock': 1,\n",
       " 'English': 8,\n",
       " 'usually': 4,\n",
       " 'appear': 36,\n",
       " 'period': 18,\n",
       " 'windows': 9,\n",
       " 'motive': 9,\n",
       " 'figures': 1,\n",
       " 'Isabella': 69,\n",
       " 'urgent': 2,\n",
       " 'deep': 14,\n",
       " 'retirement': 5,\n",
       " 'unclosed': 1,\n",
       " 'delayed': 3,\n",
       " 'attention': 59,\n",
       " 'fondest': 1,\n",
       " 'wet': 5,\n",
       " 'governed': 2,\n",
       " 'tremble': 2,\n",
       " 'bids': 1,\n",
       " 'illiterate': 2,\n",
       " 'interposition': 1,\n",
       " 'amusing': 7,\n",
       " 'hindrance': 1,\n",
       " 'tenderness': 6,\n",
       " 'sister': 33,\n",
       " 'feminine': 1,\n",
       " 'gladness': 1,\n",
       " 'disappoint': 3,\n",
       " 'surmises': 1,\n",
       " 'overpowered': 4,\n",
       " 'Dorking': 1,\n",
       " 'somewhat': 4,\n",
       " 'conscience': 8,\n",
       " 'Candles': 1,\n",
       " 'supplied': 5,\n",
       " 'eating': 7,\n",
       " 'receipt': 1,\n",
       " 'Weston': 439,\n",
       " 'grey': 1,\n",
       " 'contribute': 1,\n",
       " 'analogy': 1,\n",
       " 'rapidity': 3,\n",
       " 'hinting': 1,\n",
       " 'negligence': 1,\n",
       " 'objects': 7,\n",
       " 'planned': 2,\n",
       " 'shake': 9,\n",
       " 'accent': 5,\n",
       " 'saddle': 1,\n",
       " 'nay': 5,\n",
       " 'with': 1187,\n",
       " 'afloat': 1,\n",
       " 'softly': 1,\n",
       " 'leg': 6,\n",
       " 'inferiority': 5,\n",
       " 'promote': 4,\n",
       " 'playing': 9,\n",
       " 'delight': 21,\n",
       " 'unconcern': 1,\n",
       " 'merit': 14,\n",
       " 'accession': 1,\n",
       " 'expense': 7,\n",
       " 'Wright': 4,\n",
       " 'doom': 1,\n",
       " 'chapter': 1,\n",
       " 'grown': 9,\n",
       " 'intellects': 2,\n",
       " 'guilty': 1,\n",
       " 'neighbours': 16,\n",
       " 'pools': 1,\n",
       " 'suspecting': 5,\n",
       " 'residence': 4,\n",
       " 'need': 42,\n",
       " 'Call': 1,\n",
       " 'run': 17,\n",
       " 'interested': 15,\n",
       " 'blue': 4,\n",
       " 'enjoyment': 22,\n",
       " 'conscious': 11,\n",
       " 'poultry': 2,\n",
       " 'stipulation': 1,\n",
       " 'much': 478,\n",
       " 'pursue': 1,\n",
       " 'acknowledge': 14,\n",
       " 'debased': 1,\n",
       " 'Almane': 1,\n",
       " 'thither': 4,\n",
       " 'representation': 3,\n",
       " 'disclaiming': 1,\n",
       " 'bring': 38,\n",
       " 'proceeded': 13,\n",
       " 'Perfectly': 2,\n",
       " '_gentleman_': 1,\n",
       " 'combine': 1,\n",
       " 'sight': 26,\n",
       " 'excused': 3,\n",
       " 'indolent': 1,\n",
       " 'brain': 7,\n",
       " 'courses': 1,\n",
       " 'Weymouth': 17,\n",
       " 'removal': 7,\n",
       " 'tranquillised': 2,\n",
       " 'boiled': 5,\n",
       " 'rendering': 1,\n",
       " 'denote': 3,\n",
       " 'superiority': 10,\n",
       " 'undesigned': 1,\n",
       " 'unmodulated': 1,\n",
       " 'fatiguing': 1,\n",
       " 'presiding': 1,\n",
       " 'conduct': 27,\n",
       " 'teased': 1,\n",
       " 'acquired': 3,\n",
       " 'intervals': 1,\n",
       " '000': 2,\n",
       " 'improves': 1,\n",
       " 'bilious': 3,\n",
       " 'posture': 1,\n",
       " 'convincing': 3,\n",
       " 'lets': 1,\n",
       " 'licentiousness': 1,\n",
       " 'individually': 1,\n",
       " 'counteract': 3,\n",
       " 'gratifications': 1,\n",
       " 'indelicate': 1,\n",
       " 'root': 1,\n",
       " 'hatred': 1,\n",
       " 'unabated': 1,\n",
       " 'nnight': 1,\n",
       " 'waiters': 1,\n",
       " 'quite': 269,\n",
       " 'male': 1,\n",
       " 'step': 11,\n",
       " 'grounds': 10,\n",
       " 'glances': 1,\n",
       " 'hired': 1,\n",
       " 'misspent': 1,\n",
       " 'gentlemanlike': 5,\n",
       " 'endure': 13,\n",
       " 'considerable': 17,\n",
       " 'resisted': 2,\n",
       " 'suffers': 1,\n",
       " 'engrosses': 1,\n",
       " 'professed': 6,\n",
       " 'hotter': 2,\n",
       " 'requesting': 1,\n",
       " 'sanguine': 7,\n",
       " 'sheltered': 2,\n",
       " 'cheap': 2,\n",
       " 'coxcomb': 3,\n",
       " 'rarity': 1,\n",
       " 'dispersing': 1,\n",
       " 'belonging': 4,\n",
       " 'comforted': 3,\n",
       " 'gold': 1,\n",
       " 'thorough': 12,\n",
       " 'figured': 1,\n",
       " 'always': 235,\n",
       " 'those': 87,\n",
       " 'emphasis': 1,\n",
       " 'holiday': 2,\n",
       " 'Elegant': 3,\n",
       " 'justice': 24,\n",
       " 'unobjectionable': 1,\n",
       " 'intending': 4,\n",
       " 'forestalling': 1,\n",
       " 'screwed': 1,\n",
       " 'insipid': 1,\n",
       " 'scalloped': 1,\n",
       " 'promoting': 1,\n",
       " 'Many': 5,\n",
       " 'advantages': 12,\n",
       " 'hungry': 3,\n",
       " 'exercise': 17,\n",
       " 'tone': 24,\n",
       " 'charades': 4,\n",
       " 'mounts': 1,\n",
       " 'At': 34,\n",
       " 'styles': 1,\n",
       " 'secures': 1,\n",
       " 'popular': 1,\n",
       " 'church': 6,\n",
       " 'Dixon': 44,\n",
       " 'sweep': 5,\n",
       " 'opens': 1,\n",
       " 'rain': 22,\n",
       " 'doat': 1,\n",
       " 'evenings': 5,\n",
       " 'delineated': 1,\n",
       " 'headaches': 1,\n",
       " 'hopeless': 1,\n",
       " 'brilliant': 6,\n",
       " 'rights': 5,\n",
       " 'continued': 38,\n",
       " 'Three': 4,\n",
       " 'Perrys': 3,\n",
       " 'matters': 10,\n",
       " 'corn': 1,\n",
       " 'Sept': 1,\n",
       " 'Abbots': 1,\n",
       " 'jealousy': 5,\n",
       " 'quickly': 7,\n",
       " 'convince': 9,\n",
       " 'sentiment': 10,\n",
       " 'dissuaded': 1,\n",
       " 'conviction': 16,\n",
       " 'legal': 1,\n",
       " 'likeness': 21,\n",
       " 'questions': 12,\n",
       " 'continuing': 5,\n",
       " 'blessed': 6,\n",
       " 'pencilled': 1,\n",
       " 'custard': 1,\n",
       " 'derived': 1,\n",
       " 'People': 2,\n",
       " 'youth': 11,\n",
       " 'necessary': 36,\n",
       " 'accents': 1,\n",
       " 'indistinct': 1,\n",
       " 'lapse': 1,\n",
       " 'superior': 59,\n",
       " 'observant': 2,\n",
       " 'happy': 122,\n",
       " 'Crown': 25,\n",
       " 'predominated': 1,\n",
       " 'Beg': 1,\n",
       " 'praises': 1,\n",
       " 'reserved': 9,\n",
       " 'songs': 1,\n",
       " 'Stilton': 1,\n",
       " 'safety': 10,\n",
       " '_his_': 4,\n",
       " 'cold': 54,\n",
       " 'pretence': 9,\n",
       " 'IV': 3,\n",
       " 'purposes': 1,\n",
       " 'ulcerated': 1,\n",
       " 'neat': 6,\n",
       " 'foresight': 1,\n",
       " 'extended': 1,\n",
       " 'reading': 15,\n",
       " 'loser': 1,\n",
       " 'women': 19,\n",
       " 'home': 130,\n",
       " 'weather': 39,\n",
       " '_should_': 2,\n",
       " 'recovering': 4,\n",
       " 'shrinking': 1,\n",
       " 'treat': 2,\n",
       " 'Serious': 1,\n",
       " 'touches': 2,\n",
       " 'undoubted': 1,\n",
       " 'class': 5,\n",
       " 'thankfully': 2,\n",
       " 'Invite': 2,\n",
       " '_appropriation_': 1,\n",
       " 'cheerlessness': 1,\n",
       " 'predictions': 1,\n",
       " 'penetrated': 1,\n",
       " 'death': 10,\n",
       " 'effecting': 1,\n",
       " 'escaped': 7,\n",
       " 'finessing': 1,\n",
       " 'hearing': 32,\n",
       " 'decline': 2,\n",
       " 'infinitely': 14,\n",
       " '?--': 200,\n",
       " 'trivial': 3,\n",
       " 'displayed': 2,\n",
       " 'WINDSOR': 1,\n",
       " 'administered': 1,\n",
       " 'adherence': 1,\n",
       " 'witnessed': 4,\n",
       " ...}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = {}\n",
    "\n",
    "for sent in gutenberg.sents('austen-emma.txt'):\n",
    "    for word in sent:\n",
    "        if word in count:\n",
    "            count[word] += 1\n",
    "        else:\n",
    "            count[word] = 1\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Versión mejorada con defaultdicts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "count = defaultdict(int)\n",
    "\n",
    "for sent in gutenberg.sents('austen-emma.txt'):\n",
    "    for word in sent:\n",
    "        count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 palabras más frecuentes: [(',', 11454), ('.', 6928), ('to', 5183), ('the', 4844), ('and', 4672), ('of', 4279), ('I', 3178), ('a', 3004), ('was', 2385), ('her', 2381)]\n",
      "Vocabulario: 7806\n",
      "Tokens: 192484\n"
     ]
    }
   ],
   "source": [
    "print('10 palabras más frecuentes:', sorted(count.items(), key=lambda x: -x[1])[:10])\n",
    "print('Vocabulario:', len(count))\n",
    "print('Tokens:', sum(count.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Versión usando clase Counter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "count = Counter()\n",
    "\n",
    "for sent in gutenberg.sents('austen-emma.txt'):\n",
    "    count.update(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 palabras más frecuentes: [(',', 11454), ('.', 6928), ('to', 5183), ('the', 4844), ('and', 4672), ('of', 4279), ('I', 3178), ('a', 3004), ('was', 2385), ('her', 2381)]\n",
      "Vocabulario: 7806\n",
      "Tokens: 192484\n"
     ]
    }
   ],
   "source": [
    "print('10 palabras más frecuentes:', count.most_common()[:10])\n",
    "print('Vocabulario:', len(count))\n",
    "print('Tokens:', sum(count.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus de Texto Plano\n",
    "\n",
    "- http://www.nltk.org/api/nltk.corpus.reader.html#nltk.corpus.reader.plaintext.PlaintextCorpusReader\n",
    "- http://www.nltk.org/book/ch02.html\n",
    "\n",
    "Primero crear archivo example.txt: \"Estimados Sr. y sra. Gómez. Se los cita por el art. 32 de la ley 21.234.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class PlaintextCorpusReader in module nltk.corpus.reader.plaintext:\n",
      "\n",
      "class PlaintextCorpusReader(nltk.corpus.reader.api.CorpusReader)\n",
      " |  Reader for corpora that consist of plaintext documents.  Paragraphs\n",
      " |  are assumed to be split using blank lines.  Sentences and words can\n",
      " |  be tokenized using the default tokenizers, or by custom tokenizers\n",
      " |  specificed as parameters to the constructor.\n",
      " |  \n",
      " |  This corpus reader can be customized (e.g., to skip preface\n",
      " |  sections of specific document formats) by creating a subclass and\n",
      " |  overriding the ``CorpusView`` class variable.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      PlaintextCorpusReader\n",
      " |      nltk.corpus.reader.api.CorpusReader\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, root, fileids, word_tokenizer=WordPunctTokenizer(pattern='\\\\w+|[^\\\\w\\\\s]+', gaps=False, discard_empty=True, flags=56), sent_tokenizer=<nltk.tokenize.punkt.PunktSentenceTokenizer object at 0x7f60bb13f630>, para_block_reader=<function read_blankline_block at 0x7f60bb14f2f0>, encoding='utf8')\n",
      " |      Construct a new plaintext corpus reader for a set of documents\n",
      " |      located at the given root directory.  Example usage:\n",
      " |      \n",
      " |          >>> root = '/usr/local/share/nltk_data/corpora/webtext/'\n",
      " |          >>> reader = PlaintextCorpusReader(root, '.*\\.txt') # doctest: +SKIP\n",
      " |      \n",
      " |      :param root: The root directory for this corpus.\n",
      " |      :param fileids: A list or regexp specifying the fileids in this corpus.\n",
      " |      :param word_tokenizer: Tokenizer for breaking sentences or\n",
      " |          paragraphs into words.\n",
      " |      :param sent_tokenizer: Tokenizer for breaking paragraphs\n",
      " |          into words.\n",
      " |      :param para_block_reader: The block reader used to divide the\n",
      " |          corpus into paragraph blocks.\n",
      " |  \n",
      " |  paras(self, fileids=None)\n",
      " |      :return: the given file(s) as a list of\n",
      " |          paragraphs, each encoded as a list of sentences, which are\n",
      " |          in turn encoded as lists of word strings.\n",
      " |      :rtype: list(list(list(str)))\n",
      " |  \n",
      " |  raw(self, fileids=None)\n",
      " |      :return: the given file(s) as a single string.\n",
      " |      :rtype: str\n",
      " |  \n",
      " |  sents(self, fileids=None)\n",
      " |      :return: the given file(s) as a list of\n",
      " |          sentences or utterances, each encoded as a list of word\n",
      " |          strings.\n",
      " |      :rtype: list(list(str))\n",
      " |  \n",
      " |  words(self, fileids=None)\n",
      " |      :return: the given file(s) as a list of words\n",
      " |          and punctuation symbols.\n",
      " |      :rtype: list(str)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  CorpusView = <class 'nltk.corpus.reader.util.StreamBackedCorpusView'>\n",
      " |      A 'view' of a corpus file, which acts like a sequence of tokens:\n",
      " |      it can be accessed by index, iterated over, etc.  However, the\n",
      " |      tokens are only constructed as-needed -- the entire corpus is\n",
      " |      never stored in memory at once.\n",
      " |      \n",
      " |      The constructor to ``StreamBackedCorpusView`` takes two arguments:\n",
      " |      a corpus fileid (specified as a string or as a ``PathPointer``);\n",
      " |      and a block reader.  A \"block reader\" is a function that reads\n",
      " |      zero or more tokens from a stream, and returns them as a list.  A\n",
      " |      very simple example of a block reader is:\n",
      " |      \n",
      " |          >>> def simple_block_reader(stream):\n",
      " |          ...     return stream.readline().split()\n",
      " |      \n",
      " |      This simple block reader reads a single line at a time, and\n",
      " |      returns a single token (consisting of a string) for each\n",
      " |      whitespace-separated substring on the line.\n",
      " |      \n",
      " |      When deciding how to define the block reader for a given\n",
      " |      corpus, careful consideration should be given to the size of\n",
      " |      blocks handled by the block reader.  Smaller block sizes will\n",
      " |      increase the memory requirements of the corpus view's internal\n",
      " |      data structures (by 2 integers per block).  On the other hand,\n",
      " |      larger block sizes may decrease performance for random access to\n",
      " |      the corpus.  (But note that larger block sizes will *not*\n",
      " |      decrease performance for iteration.)\n",
      " |      \n",
      " |      Internally, ``CorpusView`` maintains a partial mapping from token\n",
      " |      index to file position, with one entry per block.  When a token\n",
      " |      with a given index *i* is requested, the ``CorpusView`` constructs\n",
      " |      it as follows:\n",
      " |      \n",
      " |        1. First, it searches the toknum/filepos mapping for the token\n",
      " |           index closest to (but less than or equal to) *i*.\n",
      " |      \n",
      " |        2. Then, starting at the file position corresponding to that\n",
      " |           index, it reads one block at a time using the block reader\n",
      " |           until it reaches the requested token.\n",
      " |      \n",
      " |      The toknum/filepos mapping is created lazily: it is initially\n",
      " |      empty, but every time a new block is read, the block's\n",
      " |      initial token is added to the mapping.  (Thus, the toknum/filepos\n",
      " |      map has one entry per block.)\n",
      " |      \n",
      " |      In order to increase efficiency for random access patterns that\n",
      " |      have high degrees of locality, the corpus view may cache one or\n",
      " |      more blocks.\n",
      " |      \n",
      " |      :note: Each ``CorpusView`` object internally maintains an open file\n",
      " |          object for its underlying corpus file.  This file should be\n",
      " |          automatically closed when the ``CorpusView`` is garbage collected,\n",
      " |          but if you wish to close it manually, use the ``close()``\n",
      " |          method.  If you access a ``CorpusView``'s items after it has been\n",
      " |          closed, the file object will be automatically re-opened.\n",
      " |      \n",
      " |      :warning: If the contents of the file are modified during the\n",
      " |          lifetime of the ``CorpusView``, then the ``CorpusView``'s behavior\n",
      " |          is undefined.\n",
      " |      \n",
      " |      :warning: If a unicode encoding is specified when constructing a\n",
      " |          ``CorpusView``, then the block reader may only call\n",
      " |          ``stream.seek()`` with offsets that have been returned by\n",
      " |          ``stream.tell()``; in particular, calling ``stream.seek()`` with\n",
      " |          relative offsets, or with offsets based on string lengths, may\n",
      " |          lead to incorrect behavior.\n",
      " |      \n",
      " |      :ivar _block_reader: The function used to read\n",
      " |          a single block from the underlying file stream.\n",
      " |      :ivar _toknum: A list containing the token index of each block\n",
      " |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      " |          token index of the first token in block ``i``.  Together\n",
      " |          with ``_filepos``, this forms a partial mapping between token\n",
      " |          indices and file positions.\n",
      " |      :ivar _filepos: A list containing the file position of each block\n",
      " |          that has been processed.  In particular, ``_toknum[i]`` is the\n",
      " |          file position of the first character in block ``i``.  Together\n",
      " |          with ``_toknum``, this forms a partial mapping between token\n",
      " |          indices and file positions.\n",
      " |      :ivar _stream: The stream used to access the underlying corpus file.\n",
      " |      :ivar _len: The total number of tokens in the corpus, if known;\n",
      " |          or None, if the number of tokens is not yet known.\n",
      " |      :ivar _eofpos: The character position of the last character in the\n",
      " |          file.  This is calculated when the corpus view is initialized,\n",
      " |          and is used to decide when the end of file has been reached.\n",
      " |      :ivar _cache: A cache of the most recently read block.  It\n",
      " |         is encoded as a tuple (start_toknum, end_toknum, tokens), where\n",
      " |         start_toknum is the token index of the first token in the block;\n",
      " |         end_toknum is the token index of the first token not in the\n",
      " |         block; and tokens is a list of the tokens in the block.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from nltk.corpus.reader.api.CorpusReader:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __unicode__ = __str__(self, /)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  abspath(self, fileid)\n",
      " |      Return the absolute path for the given file.\n",
      " |      \n",
      " |      :type fileid: str\n",
      " |      :param fileid: The file identifier for the file whose path\n",
      " |          should be returned.\n",
      " |      :rtype: PathPointer\n",
      " |  \n",
      " |  abspaths(self, fileids=None, include_encoding=False, include_fileid=False)\n",
      " |      Return a list of the absolute paths for all fileids in this corpus;\n",
      " |      or for the given list of fileids, if specified.\n",
      " |      \n",
      " |      :type fileids: None or str or list\n",
      " |      :param fileids: Specifies the set of fileids for which paths should\n",
      " |          be returned.  Can be None, for all fileids; a list of\n",
      " |          file identifiers, for a specified set of fileids; or a single\n",
      " |          file identifier, for a single file.  Note that the return\n",
      " |          value is always a list of paths, even if ``fileids`` is a\n",
      " |          single file identifier.\n",
      " |      \n",
      " |      :param include_encoding: If true, then return a list of\n",
      " |          ``(path_pointer, encoding)`` tuples.\n",
      " |      \n",
      " |      :rtype: list(PathPointer)\n",
      " |  \n",
      " |  citation(self)\n",
      " |      Return the contents of the corpus citation.bib file, if it exists.\n",
      " |  \n",
      " |  encoding(self, file)\n",
      " |      Return the unicode encoding for the given corpus file, if known.\n",
      " |      If the encoding is unknown, or if the given file should be\n",
      " |      processed using byte strings (str), then return None.\n",
      " |  \n",
      " |  ensure_loaded(self)\n",
      " |      Load this corpus (if it has not already been loaded).  This is\n",
      " |      used by LazyCorpusLoader as a simple method that can be used to\n",
      " |      make sure a corpus is loaded -- e.g., in case a user wants to\n",
      " |      do help(some_corpus).\n",
      " |  \n",
      " |  fileids(self)\n",
      " |      Return a list of file identifiers for the fileids that make up\n",
      " |      this corpus.\n",
      " |  \n",
      " |  license(self)\n",
      " |      Return the contents of the corpus LICENSE file, if it exists.\n",
      " |  \n",
      " |  open(self, file)\n",
      " |      Return an open stream that can be used to read the given file.\n",
      " |      If the file's encoding is not None, then the stream will\n",
      " |      automatically decode the file's contents into unicode.\n",
      " |      \n",
      " |      :param file: The file identifier of the file to read.\n",
      " |  \n",
      " |  readme(self)\n",
      " |      Return the contents of the corpus README file, if it exists.\n",
      " |  \n",
      " |  unicode_repr = __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from nltk.corpus.reader.api.CorpusReader:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  root\n",
      " |      The directory where this corpus is stored.\n",
      " |      \n",
      " |      :type: PathPointer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import PlaintextCorpusReader\n",
    "\n",
    "help(PlaintextCorpusReader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = PlaintextCorpusReader('.', 'example.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Estimados', 'Sr', '.', 'y', 'sra', '.'],\n",
       " ['Gómez', '.'],\n",
       " ['Se', 'los', 'cita', 'por', 'el', 'art', '.'],\n",
       " ['32', 'de', 'la', 'ley', '21', '.', '234', '.']]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(corpus.sents())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenización\n",
    "\n",
    "- http://www.nltk.org/api/nltk.tokenize.html#nltk.tokenize.regexp.RegexpTokenizer\n",
    "- http://www.nltk.org/book/ch03.html#regular-expressions-for-tokenizing-text\n",
    "\n",
    "De la documentación de NLTK obtenemos una expresión regular para tokenizar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'''(?x)    # set flag to allow verbose regexps\n",
    "     (?:[A-Z]\\.)+        # abbreviations, e.g. U.S.A.\n",
    "   | \\w+(?:-\\w+)*        # words with optional internal hyphens\n",
    "   | \\$?\\d+(?:\\.\\d+)?%?  # currency and percentages, e.g. $12.40, 82%\n",
    "   | \\.\\.\\.            # ellipsis\n",
    "   | [][.,;\"'?():-_`]  # these are separate tokens; includes ], [\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo probamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Estimados', 'Sr', '.', 'y', 'sra', '.'],\n",
       " ['Gómez', '.'],\n",
       " ['Se', 'los', 'cita', 'por', 'el', 'art', '.'],\n",
       " ['32', 'de', 'la', 'ley', '21', '.', '234', '.']]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(pattern)\n",
    "\n",
    "corpus = PlaintextCorpusReader('.', 'example.txt', word_tokenizer=tokenizer)\n",
    "list(corpus.sents())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que tokeniza mal todas las abreviaciones y el número \"21.234\".\n",
    "Mejoramos la expresión regular y probamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Estimados', 'Sr.', 'y', 'sra.'],\n",
       " ['Gómez', '.'],\n",
       " ['Se', 'los', 'cita', 'por', 'el', 'art.'],\n",
       " ['32', 'de', 'la', 'ley', '21.234', '.']]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = r'''(?x)    # set flag to allow verbose regexps\n",
    "   (?:\\d{1,3}(?:\\.\\d{3})+)  # numbers with '.' in the middle\n",
    "   | (?:[Ss]r\\.|[Ss]ra\\.|art\\.)  # common spanish abbreviations\n",
    "   | (?:[A-Z]\\.)+        # abbreviations, e.g. U.S.A.\n",
    "   | \\w+(?:-\\w+)*        # words with optional internal hyphens\n",
    "   | \\$?\\d+(?:\\.\\d+)?%?  # currency and percentages, e.g. $12.40, 82%\n",
    "   | \\.\\.\\.            # ellipsis\n",
    "   | [][.,;\"'?():-_`]  # these are separate tokens; includes ], [\n",
    "'''\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(pattern)\n",
    "\n",
    "corpus = PlaintextCorpusReader('.', 'example.txt', word_tokenizer=tokenizer)\n",
    "list(corpus.sents())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tokeniza bien!!\n",
    "\n",
    "(La segmentación en oraciones sigue estando mal, pero resolver eso queda fuera de esta clase.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
